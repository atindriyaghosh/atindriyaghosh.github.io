<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8" />
    <!-- (1) Optimize for mobile versions: http://goo.gl/EOpFl -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <!-- (1) force latest IE rendering engine: bit.ly/1c8EiC9 -->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Recommendation Systems 2 - Similarity Scores</title>
    <meta name="description" content="Techniques to calculate Similarity Scores for Recommendation Systems" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="MobileOptimized" content="320" />
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Recommendation Systems 2 - Similarity Scores">
    <meta name="twitter:description" content="Techniques to calculate Similarity Scores for Recommendation Systems">
    <meta name="twitter:site" content="https://www.atindriyaghosh.com">
    <meta name="twitter:creator" content="@A3Ghosh">
    <meta name="google-site-verification" content="">
    <meta property="fb:admins" content="">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Recommendation Systems 2 - Similarity Scores">
    <meta property="og:description" content="Techniques to calculate Similarity Scores for Recommendation Systems">

    <link rel="shortcut icon" href="../favicon.ico">
    <link rel="stylesheet" href="../assets/js/styles/obsidian.css">
    <link rel="stylesheet" href="http://brick.a.ssl.fastly.net/Linux+Libertine:400,400i,700,700i/Open+Sans:400,400i,700,700i">
    <link href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.min.css" rel="stylesheet">
    <link rel="stylesheet" type="text/css" media="screen" href="../assets/css/main.css" />
    <link rel="stylesheet" type="text/css" media="print" href="../assets/css/print.css" />
	<!-- Pushy CSS -->
    <link rel="stylesheet" href="../assets/css/pushy.css">
    <script src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
    <link rel="canonical" href="https://www.atindriyaghosh.com/recommendation-systems-2-similarity-scores/" />
    
    <meta property="og:site_name" content="Atindriya Ghosh" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Recommendation Systems 2 - Similarity Scores" />
    <meta property="og:description" content="Techniques to calculate Similarity Scores for Recommendation Systems..." />
    <meta property="og:url" content="https://www.atindriyaghosh.com/recommendation-systems-2-similarity-scores/" />
    <meta property="article:published_time" content="2014-09-28T06:15:00.000Z" />
    <meta property="article:modified_time" content="2015-02-10T18:04:16.976Z" />
    <meta property="article:tag" content="Python" />
    <meta property="article:tag" content="Recommendation Systems" />
    <meta property="article:tag" content="Collaborative Filtering" />
    <meta property="article:tag" content="Machine Learning" />
    <meta property="article:tag" content="Similarity Scores" />
    
    <meta name="twitter:card" content="content" />
    <meta name="twitter:title" content="Recommendation Systems 2 - Similarity Scores" />
    <meta name="twitter:description" content="Techniques to calculate Similarity Scores for Recommendation Systems..." />
    <meta name="twitter:url" content="https://www.atindriyaghosh.com/recommendation-systems-2-similarity-scores/" />
    
    <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Article",
    "publisher": "Atindriya Ghosh",
    "author": {
        "@type": "Person",
        "name": "Atindriya Ghosh",
        "image": "https://www.atindriyaghosh.com/content/images/2015/02/Self-1.jpg",
        "url": "https://www.atindriyaghosh.com/author/atindriya-ghosh",
        "sameAs": null
    },
    "headline": "Recommendation Systems 2 - Similarity Scores",
    "url": "https://www.atindriyaghosh.com/recommendation-systems-2-similarity-scores/",
    "datePublished": "2014-09-28T06:15:00.000Z",
    "dateModified": "2015-02-10T18:04:16.976Z",
    "keywords": "Python, Recommendation Systems, Collaborative Filtering, Machine Learning, Similarity Scores",
    "description": "Techniques to calculate Similarity Scores for Recommendation Systems"
}
    </script>

    <meta name="generator" content="Ghost 0.5" />
    <link rel="alternate" type="application/rss+xml" title="Atindriya Ghosh" href="../rss" />
</head>
<body class="post-template tag-python tag-recommendation-systems tag-collaborative-filtering tag-machine-learning tag-similarity-scores">
	<!-- Pushy Menu -->
    <nav class="pushy pushy-left">
        <ul>
			<li><a href=".."><span class="fa fa-home fa-2x"></span>&nbsp;&nbsp;&nbsp;&nbsp;Home</a></li>
            <li><a href="../aboutme"><span class="fa fa-user fa-2x"></span>&nbsp;&nbsp;&nbsp;&nbsp;About Me</a></li>
			<li>
			<div id="at_search">
				<form>
				  <input type="text" id="search-field" placeholder="Search" autocomplete="off" />
				</form>
				<div id="results" class="at_search_results"></div>
			</div>
			</li>
        </ul>
    </nav>

    <!-- Site Overlay -->
    <div class="site-overlay"></div>
	
	<div id="container">
		<!-- Menu Button -->
		<div class="menu-btn logo-readium logo"><span class="logo"></span></div>
		

<main role="main">
	<!-- Added this fix since IE doesn't support main tag -->
	<div class="content">

		<article class="post tag-python tag-recommendation-systems tag-collaborative-filtering tag-machine-learning tag-similarity-scores">



			<div class="noarticleimage">
				<div class="post-meta">
					<h1 class="post-title">Recommendation Systems 2 - Similarity Scores</h1>
					<div class="cf post-meta-text">
						<div class="author-image" style="background-image: url(../content/images/2015/02/Self-1.jpg)">Blog Logo</div>
						<h4 class="author-name" itemprop="author" itemscope itemtype="http://schema.org/Person"><a href="../author/atindriya-ghosh">Atindriya Ghosh</a></h4> on
						<time datetime="2014-09-28">28 Sep 2014</time>, tagged on <span class="post-tag-python"><a href="../tag/python">Python</a></span><span class="post-tag-recommendation-systems">, <a href="../tag/recommendation-systems">Recommendation Systems</a></span><span class="post-tag-collaborative-filtering">, <a href="../tag/collaborative-filtering">Collaborative Filtering</a></span><span class="post-tag-machine-learning">, <a href="../tag/machine-learning">Machine Learning</a></span><span class="post-tag-similarity-scores">, <a href="../tag/similarity-scores">Similarity Scores</a></span>
					</div>
				</div>
			</div>
			<br>
			<br>
			<br>



				<section class="post-content">
					<div class="post-reading">
						<span class="post-reading-time"></span> read
					</div>
					<a name="topofpage"></a>
					<p>This post is a continuation of my previous post on <a href="https://www.atindriyaghosh.com/recommendation-systems-1-collaborative-filtering/" title="Collaborative Filtering">Collaborative Filtering</a>. In this post, I will detail some of the techniques available for calculating similarity scores.</p>

<h1 id="aquickrecap">A Quick Recap</h1>

<p>Collaborative Filtering (CF) is a technique used in creating recommendation systems. This technique relies on a dataset of user preferences to provide recommendations to individual users.</p>

<p>There are three categories of CF algorithms - User-based, Item-based and Hybrid. </p>

<ol>
<li>User-based algorithms calculate the most similar users to a specific user and use this data to generate recommendations  </li>
<li>Item-based algorithms create a model of the relationships between items and calculate recommendations based on this model  </li>
<li>Hybrid algorithms combine both of the above approaches</li>
</ol>

<p>The similarity between users is calculated based on a metric known as similarity score. The rest of the post will focus on three algorithms that are used to determine similarity score.</p>

<h1 id="similarityscorealgorithms">Similarity Score Algorithms</h1>

<p>There are many algorithms that can be used to calculate similarity scores. For the purposes of this post, I will cover only the following three algorithms</p>

<ol>
<li>Euclidean Distance-based Score  </li>
<li>Pearson Correlation Score  </li>
<li>Cosine Similarity Score</li>
</ol>

<p>All of these algorithms calculate a similarity score where a higher number indicates greater similarity. Since the similarity scores are normalized the highest similarity score is 1, which indicates that two users are identical.</p>

<h2 id="euclideandistancebasedscore">Euclidean Distance-based Score</h2>

<h3 id="concept">Concept</h3>

<p>Euclidean distance is the straight line distance between two points. Consider a graph with only 2 axes which correspond to user ratings of 2 movies, i.e., the X-axis corresponds to the user ratings of the movie 'Seven Samurai' and the Y-axis corresponds to the user ratings of 'Taxi Driver'. If we have 2 users, User and User2, and plot them according to their ratings for these two movies on the graph, we would get something like this</p>

<p><img src="../content/images/2015/02/Euclidean-Distance-Score.png" alt="alt Euclidean Distance Score" /></p>

<p>As shown in the graph above, the Euclidean distance is the straight-line distance between the two users.</p>

<p>The mathematical formula to calculate it is</p>

<p>$d(x,y) = \sqrt{ \sum\limits_{i=1}^n (x_i - y_i)^2}$</p>

<p>While similarity is the measure of how similar items are, distance is the measure of their dissimilarity. Thus, the Euclidean distance between User1 and User2 tells us how dissimilar they are. In order to use this information in our Recommendation system, we have to convert it to a similarity metric.</p>

<p>Thus, the mathematical expression to convert the Euclidean distance-based similarity score is</p>

<p>$\dfrac{1}{1 + \sqrt{ \sum\limits_{i=1}^n (x_i - y_i)^2}}$</p>

<h3 id="implementation">Implementation</h3>

<p>Consider a simple dataset of movie ratings with  users - User1 and User2</p>

<pre><code>ratings = {
    'User1': {
        'Seven Samurai': 4, 'Taxi Driver': 3,
        'Usual Suspects, The': 3, 'Clerks': 1,
        'Batman Forever': 2, 'Nosferatu': 4},
    'User2': {
        'Seven Samurai': 2, 'Taxi Driver': 4,
        'Usual Suspects, The': 5, 'Clerks': 3,
        'Batman Forever': 1}}    
</code></pre>

<p>The Python snippet will calculate the Euclidean Distance on only those movies that both the users have added ratings for.</p>

<p>The snippet to calculate the similarity is</p>

<pre><code>def calcEuclideanSim(user1, user2):
    # Get the list of similar movies
    similarMovies = [movie for movie in ratings[user1]
                     if movie in ratings[user2]]

    # If there are similar movies calculate similarity score, else similarity score is 0
    similarityScore = 0 
    if(len(similarMovies) != 0):
        euclDistance = Decimal(sum(
            pow(ratings[user1][movie] - ratings[user2][movie], 2)
            for movie in similarMovies))

        similarityScore = 1 / (1 + euclDistance)

    return similarityScore
</code></pre>

<h2 id="pearsoncorrelationscore">Pearson Correlation Score</h2>

<h3 id="concept">Concept</h3>

<p>The Pearson Correlation score is used to understand the linear correlation between datasets which in turn helps us understand their similarity. Consider the following graph which has 2 axes - the X-axis for User1 and the Y-axis for User2. Thus, each point on the graph corresponds to the user ratings for a specific movie.</p>

<p><img src="../content/images/2015/02/Pearson-Correlation-Score.png" alt="alt Pearson Correlation Score" /></p>

<p>The shown best-fit line is the straight line that best fits all the data points of the two datasets. The slope of this best-fit line gives us the correlation between the two datasets. The values for the Pearson Correlation range from -1 to +1 where -1 indicates no correlation i.e. no similarity and +1 indicates perfect correlation i.e. perfect similarity.</p>

<p>The mathematical formula to calculate Pearson Correlation score is</p>

<p>$r = \dfrac{n(\sum\limits_{i=1}^n x_iy_i) + (\sum\limits_{i=1}^n x_i) (\sum\limits_{i=1}^n y_i)}{\sqrt{[n\sum\limits_{i=1}^n x_i^2 - (\sum\limits_{i=1}^n x_i)^2][n\sum\limits_{i=1}^n y_i^2 - (\sum\limits_{i=1}^n y_i)^2]}}$</p>

<h5 id="gradeinflation">Grade Inflation</h5>

<p>In the real world, users are human beings that have differing opinions about the meaning of different ratings. User1 might be more lenient in her ratings and give a rating of 3 to a movie she considers average. On the other hand, User2 might be harsher and for her an average movie deserves a rating of 2.</p>

<p>This variance is known as Grade Inflation. While the previous Euclidean approach does not address this issue, the Pearson Correlation score is one algorithm which can be used to fix this problem.</p>

<h3 id="implementation">Implementation</h3>

<p>Let us again take the above datasets of User1 and User2 such that</p>

<pre><code>ratings = {
    'User1': {
        'Seven Samurai': 4, 'Taxi Driver': 3,
        'Usual Suspects, The': 3, 'Clerks': 1,
        'Batman Forever': 2, 'Nosferatu': 4},
    'User2': {
        'Seven Samurai': 2, 'Taxi Driver': 4,
        'Usual Suspects, The': 5, 'Clerks': 3,
        'Batman Forever': 1}}   
</code></pre>

<p>The Python snippet calculate Pearson Correlation is</p>

<pre><code>def calcPearsonSim(user1, user2):
    def calcSqrtExpr(n, a, b):
        return sqrt(n * a - pow(b, 2))
    prodSum = 0
    sum1 = 0
    sum2 = 0
    sum1Sq = 0
    sum2Sq = 0
    n = 0
    for movie in ratings[user1]:
        if movie in ratings[user2]:
            rating1 = ratings[user1][movie]
            rating2 = ratings[user2][movie]
            prodSum += rating1 * rating2
            sum1 += rating1
            sum2 += rating2
            sum1Sq += pow(rating1, 2)
            sum2Sq += pow(rating2, 2)
            n += 1
    ## Calculate numerator
    num = n * prodSum - sum1 * sum2

    ## Calculate denominator
    denom = calcSqrtExpr(n, sum1Sq, sum1) * calcSqrtExpr(n, sum2Sq, sum2)
    r = 0
    if denom &gt; 0:
        r = num / denom
    return r
</code></pre>

<h2 id="cosinesimilarityscore">Cosine Similarity Score</h2>

<h3 id="concept">Concept</h3>

<p>Cosine Similarity is the the cosine measure between two vectors i.e. if we have two vectors User1 and User2 then their Cosine Similarity is the cosine of the angle between the two vectors.</p>

<p>Consider 2 vectors User1 and User2 with only 2 elements corresponding to the ratings for the movies 'Seven Samurai' and 'Taxi Driver' as shown below</p>

<p><img src="../content/images/2015/02/Cosine-Similarity-Score.png" alt="alt Cosine Similarity Score" /></p>

<p>The Cosine Similarity is the cosine of the angle between User1 and User2.</p>

<p>The mathematical expression to calculate Cosine Similarity is</p>

<p>$cos(x, y) = \dfrac{\sum\limits_{i=1}^n x_iy_i}{\sqrt{\sum\limits_{i=1}^n x_i^2} \sqrt{\sum\limits_{i=1}^n x_i^2}}$</p>

<h3 id="implementation">Implementation</h3>

<p>We use the same dataset for User1 and User2 again</p>

<pre><code>ratings = {
    'User1': {
        'Seven Samurai': 4, 'Taxi Driver': 3,
        'Usual Suspects, The': 3, 'Clerks': 1,
        'Batman Forever': 2, 'Nosferatu': 4},
    'User2': {
        'Seven Samurai': 2, 'Taxi Driver': 4,
        'Usual Suspects, The': 5, 'Clerks': 3,
        'Batman Forever': 1}}   
</code></pre>

<p>and the list of all the movies</p>

<pre><code>movies = ['Seven Samurai', 'Taxi Driver',
      'Usual Suspects, The', 'Clerks',
      'Batman Forever', 'Nosferatu']
</code></pre>

<p>The Python code will be</p>

<pre><code>def calcCosineSim(user1, user2):
    def calcLength(user):
        return sqrt(sum(
            pow(ratings[user][movie], 2) for movie in ratings[
                user]))
    user1Length = calcLength(user1)
    user2Length = calcLength(user2)
    dotProd = 0
    for movie in movies:
        dotProd += ratings[user1].get(
            movie, 0) * ratings[user2].get(
            movie, 0)

    similarityScore = dotProd / (user1Length * user2Length)

    return similarityScore
</code></pre>

<h1 id="conclusion">Conclusion</h1>

<p>Thus, I have covered 3 algorithms used to calculate similarity scores and their corresponding Python code. But, calculating these scores is only an intermediate step in generating recommendations. In the next post, I will show how we can use these similarity scores to actually generate recommendations for users. </p>

<h1 id="references">References</h1>

<ol>
<li><a href="http://www.amazon.com/Programming-Collective-Intelligence-Building-Applications/dp/0596529325" title="Programming Collective Intelligence">Programming Collective Intelligence</a>  </li>
<li><a href="http://guidetodatamining.com/" title="A Programmer's Guide to Data Mining">A Programmer's Guide to Data Mining</a></li>
</ol>
				</section>
				<footer class="post-footer">
					<section class="share">
						<a class="icon-twitter" href="http://twitter.com/share?text=Recommendation%20Systems%202%20-%20Similarity%20Scores&url=https://www.atindriyaghosh.com/recommendation-systems-2-similarity-scores/"
							onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
							<span class="hidden">Twitter</span>
						</a>
						<a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https://www.atindriyaghosh.com/recommendation-systems-2-similarity-scores/"
							onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
							<span class="hidden">Facebook</span>
						</a>
						<a class="icon-google-plus" href="https://plus.google.com/share?url=https://www.atindriyaghosh.com/recommendation-systems-2-similarity-scores/"
						   onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
							<span class="hidden">Google+</span>
						</a>
					</section>
				</footer>
				<div class="bottom-teaser cf">
					<div class="isLeft">
						<h5 class="index-headline featured"><span>Written by</span></h5>
						<section class="author">
							<div class="author-image" style="background-image: url(../content/images/2015/02/Self-1.jpg)">Blog Logo</div>
							<h4><a href="../author/atindriya-ghosh">Atindriya Ghosh</a></h4>
							<p class="bio">Atindriya is a Java Developer currently working with Accenture. He mostly works with and writes about Big Data Technologies</p>
							<hr>
							<p class="published">
								<a class="fa fa-twitter fa-2x" href="https://twitter.com/A3Ghosh" target="_blank">
								</a>
								<a class="fa fa-google-plus fa-2x" href="https://plus.google.com/+AtindriyaGhosh1989?rel=author" target="_blank">
								</a>
								<a class="fa fa-linkedin-square fa-2x" href="http://in.linkedin.com/in/atindriyaghosh/" target="_blank">
								</a>
								<a class="fa fa-github fa-2x" href="https://github.com/atindriyaghosh" target="_blank">
								</a>
								<a class="fa fa-rss-square fa-2x" href="http://feedpress.me/atindriyaghosh" target="_blank">
								</a>							
							</p>
						</section>
					</div>
					<div class="isRight">
						<h5 class="index-headline featured"><span>License</span></h5>
						<footer class="site-footer">
							<div class="inner">
								<section class="copyright"><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons Licence" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />&copy; 2015 by <a href="..">Atindriya Ghosh</a>.<br/>This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.</section>
								<br/>
							</div>
							<section class="poweredby">Proudly published with <a class="icon-ghost" href="http://ghost.org"> Ghost</a></section>
						</footer>
					</div>
				</div>
				
				<div id="disqus_thread"></div>
				<script type="text/javascript">
				    var disqus_shortname = 'atindriyaghosh'; // required: replace example with your forum shortname
				
				    (function() {
				        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
				        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
				        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
				    })();
				</script>
				<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

		</article>
	</div>
</main>

<div class="bottom-closer">
    <div class="background-closer-image" style="background-image: url(../content/images/2015/02/2230472EC0-1.jpg)">
        Image
    </div>
    <div class="inner">
        <h1 class="blog-title">Atindriya Ghosh</h1>
        <h2 class="blog-description">Hi, I&#x27;m Atin and welcome to my blog! I primarily write about things I learn in my day job as a Java developer. Feel free to look around and share your thoughts.</h2>
        <a href=".." class="btn">Back to Home</a>
    </div>
</div>

	</div>
    <script src="../public/jquery.js"></script>
	
    <script type="text/javascript" src="../assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="../assets/js/index.js"></script>
    <script src="../assets/js/readingTime.min.js"></script>
    <script src="../assets/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
	<script type="text/javascript" src="../assets/js/google-analytics.js"></script>
	
	<!-- Pushy JS -->
    <script type="text/javascript" src="../assets/js/min/pushy.min.js"></script>
	
	<!-- Ghosthunter JS -->
	<script type="text/javascript" src="../assets/js/min/jquery.ghostHunter.min.js"></script>
	<script type="text/javascript" src="../assets/js/ghostHunter-init.js"></script>
	
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>

</body>
</html>
